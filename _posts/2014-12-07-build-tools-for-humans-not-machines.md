---
title: "Build Tools for Humans, not Machines"
layout: post
category: en
---

> The real question is not whether machines think but whether men do. (*B. F. Skinner*)

Stephen Hawking recently [expressed his fear](http://www.telegraph.co.uk/technology/news/11268738/Artificial-intelligence-could-mean-end-of-human-race-says-Stephen-Hawking.html) that the development of AI could spell the end of human race. It might be real. It might be real, as Howking described, in the way that machines "become self-aware and 'supersede' humanity". However, It might also be real in the way that humans think and use tools more and more like machines, and finally we cannot differenciate us and them.

I hope I'm just saying a funny joke here, but the trend of the former is really obvious. Take what I'm working on, [a news reader](http://reread.io), as an example. There are [many](http://en.wikipedia.org/wiki/Prismatic_%28app%29) [news](http://link.springer.com/chapter/10.1007%2F11914853_62#page-1) [readers](http://blog.algorithmia.com/post/93293999119/create-your-own-machine-learning-powered-rss) out there on the Internet that take advantages of Machine Learning, a branch of AI. They have done great jobs in predicting what you might like best for the next article. As it has been said, reading things based on what one likes "makes people feel much better of the world".

However, together with the convenience, as they only provide the ability for you to choose categories or news sources,

For websites and applications on the Internet, the case is always that all invoving parts do things what they are good at and what they should do. When we add AI to our awesome tools, we may really need to ask ourselves. What are we really trying to predict here? Do we need to get the users to make decisions first?, or **are we treating our users as humans?**
